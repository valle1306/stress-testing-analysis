{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4f592e2",
   "metadata": {},
   "source": [
    "* Step 1: daily merge - merging all of the modalities together-- for easy access -- per participant\n",
    "* Step 2: Concatenate days : one dataframe per participant\n",
    "* Step 3: Attach metadata: Add participant_id, optional time window info\n",
    "* Step 4: Stack participants: combine all into one final dataset for ML and EDA\n",
    "* Step 5: Merge in stress labels using algined timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4c8d7460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved: C:/Users/lpnhu/Downloads/Stress_Testing_Analysis/data/raw_biomarkers/Participant 9\\cleaned\\cleaned_2023-12-16.csv\n",
      "‚úÖ Saved: C:/Users/lpnhu/Downloads/Stress_Testing_Analysis/data/raw_biomarkers/Participant 9\\cleaned\\cleaned_2023-12-17.csv\n",
      "‚úÖ Saved: C:/Users/lpnhu/Downloads/Stress_Testing_Analysis/data/raw_biomarkers/Participant 9\\cleaned\\cleaned_2023-12-18.csv\n",
      "‚úÖ Saved: C:/Users/lpnhu/Downloads/Stress_Testing_Analysis/data/raw_biomarkers/Participant 9\\cleaned\\cleaned_2023-12-19.csv\n",
      "‚úÖ Saved: C:/Users/lpnhu/Downloads/Stress_Testing_Analysis/data/raw_biomarkers/Participant 9\\cleaned\\cleaned_2023-12-20.csv\n",
      "‚úÖ Saved: C:/Users/lpnhu/Downloads/Stress_Testing_Analysis/data/raw_biomarkers/Participant 9\\cleaned\\cleaned_2023-12-21.csv\n",
      "‚úÖ Saved: C:/Users/lpnhu/Downloads/Stress_Testing_Analysis/data/raw_biomarkers/Participant 9\\cleaned\\cleaned_2023-12-22.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Path to the participant folder (e.g., \"Participant 1\")\n",
    "parent_dir = \"C:/Users/lpnhu/Downloads/Stress_Testing_Analysis/data/raw_biomarkers/Participant 9\"\n",
    "output_dir = os.path.join(parent_dir, \"cleaned\")\n",
    "\n",
    "# Create the 'cleaned' subfolder if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Identify date folders like '2023-12-24'\n",
    "day_folders = sorted([\n",
    "    f for f in os.listdir(parent_dir)\n",
    "    if os.path.isdir(os.path.join(parent_dir, f)) and f.startswith(\"2023\")\n",
    "])\n",
    "\n",
    "for day in day_folders:\n",
    "    day_path = os.path.join(parent_dir, day)\n",
    "    daily_dfs = []\n",
    "\n",
    "    for root, dirs, files in os.walk(day_path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".csv\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    df = pd.read_csv(file_path)\n",
    "                    if \"missing_value_reason\" in df.columns:\n",
    "                        df = df[df[\"missing_value_reason\"] != \"device_not_recording\"]\n",
    "                    daily_dfs.append(df)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Failed to read {file_path}: {e}\")\n",
    "\n",
    "    if not daily_dfs:\n",
    "        print(f\"‚ö†Ô∏è No valid CSV files found in {day}\")\n",
    "        continue\n",
    "\n",
    "    # Merge and clean\n",
    "    merged_df = pd.concat(daily_dfs, axis=1)\n",
    "    merged_df = merged_df.loc[:, ~merged_df.columns.duplicated()]\n",
    "    merged_df = merged_df.dropna(axis=1, how='all')\n",
    "\n",
    "    # Drop optional columns if they exist\n",
    "    merged_df = merged_df.drop(columns=[\n",
    "        col for col in ['timestamp_unix', 'participant_full_id'] if col in merged_df.columns\n",
    "    ])\n",
    "\n",
    "    # Convert timestamp and extract hour/minute\n",
    "    if 'timestamp_iso' in merged_df.columns:\n",
    "        try:\n",
    "            merged_df['timestamp_iso'] = pd.to_datetime(merged_df['timestamp_iso'], errors='coerce')\n",
    "            merged_df['hour'] = merged_df['timestamp_iso'].dt.hour\n",
    "            merged_df['minute'] = merged_df['timestamp_iso'].dt.minute\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Failed to parse timestamp for {day}: {e}\")\n",
    "\n",
    "    # Save cleaned file\n",
    "    output_path = os.path.join(output_dir, f\"cleaned_{day}.csv\")\n",
    "    merged_df.to_csv(output_path, index=False)\n",
    "    print(f\"‚úÖ Saved: {output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a450c38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "698cabb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "input_dir = \"C:/Users/lpnhu/Downloads/Stress_Testing_Analysis/data/raw_biomarkers/Participant 9/cleaned\"\n",
    "output_dir = \"C:/Users/lpnhu/Downloads/Stress_Testing_Analysis/data/cleaned_biomarkers/cleaned_09\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for fname in os.listdir(input_dir):\n",
    "    if not fname.endswith(\".csv\"):\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(os.path.join(input_dir, fname))\n",
    "\n",
    "    # Clean columns\n",
    "    df.columns = df.columns.str.replace(r\"^001_\", \"\", regex=True)\n",
    "    df.columns = df.columns.str.replace(r\"\\.\\d+$\", \"\", regex=True)\n",
    "    df = df.loc[:, ~df.columns.duplicated()]\n",
    "\n",
    "    # Save cleaned version\n",
    "    df.to_csv(os.path.join(output_dir, fname), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c072baa",
   "metadata": {},
   "source": [
    "### Check NA values in cleaned files before moving on\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "590cd024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved NA summary to participant9_na_summary.csv\n",
      "üîç Columns with highest average missingness:\n",
      "missing_value_reason     96.000000\n",
      "prv_rmssd_ms             80.557143\n",
      "respiratory_rate_brpm    79.300000\n",
      "sleep_detection_stage     3.642857\n",
      "body_position_right       3.485714\n",
      "body_position_left        3.485714\n",
      "vector_magnitude          3.428571\n",
      "activity_class            3.428571\n",
      "activity_counts           3.428571\n",
      "activity_intensity        3.428571\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "cleaned_dir = \"C:/Users/lpnhu/Downloads/Stress_Testing_Analysis/data/cleaned_biomarkers/cleaned_09\"\n",
    "na_summary = []\n",
    "\n",
    "# Loop through each cleaned daily file\n",
    "for file in sorted(os.listdir(cleaned_dir)):\n",
    "    if file.endswith(\".csv\"):\n",
    "        file_path = os.path.join(cleaned_dir, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Calculate % missing for each column\n",
    "        na_percent = df.isna().mean() * 100\n",
    "        na_row = na_percent.round(1).to_dict()\n",
    "        na_row[\"file\"] = file\n",
    "        na_summary.append(na_row)\n",
    "\n",
    "# Convert to DataFrame\n",
    "na_df = pd.DataFrame(na_summary)\n",
    "na_df.set_index(\"file\", inplace=True)\n",
    "\n",
    "# Show columns with highest average NA %\n",
    "avg_na = na_df.mean().sort_values(ascending=False)\n",
    "\n",
    "# Save for inspection\n",
    "na_df.to_csv(\"participant9_na_summary.csv\")\n",
    "print(\"‚úÖ Saved NA summary to participant9_na_summary.csv\")\n",
    "\n",
    "# Preview worst offenders\n",
    "print(\"üîç Columns with highest average missingness:\")\n",
    "print(avg_na.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0ac1edb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>timestamp_iso</th>\n",
       "      <th>accelerometers_std_g</th>\n",
       "      <th>missing_value_reason</th>\n",
       "      <th>counts_x_axis</th>\n",
       "      <th>counts_y_axis</th>\n",
       "      <th>counts_z_axis</th>\n",
       "      <th>vector_magnitude</th>\n",
       "      <th>activity_class</th>\n",
       "      <th>activity_counts</th>\n",
       "      <th>...</th>\n",
       "      <th>met</th>\n",
       "      <th>prv_rmssd_ms</th>\n",
       "      <th>pulse_rate_bpm</th>\n",
       "      <th>respiratory_rate_brpm</th>\n",
       "      <th>sleep_detection_stage</th>\n",
       "      <th>step_counts</th>\n",
       "      <th>temperature_celsius</th>\n",
       "      <th>wearing_detection_percentage</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cleaned_2023-12-16.csv</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>99.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>96.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>87.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cleaned_2023-12-17.csv</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cleaned_2023-12-18.csv</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>99.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>88.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cleaned_2023-12-19.csv</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>97.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>79.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>79.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cleaned_2023-12-20.csv</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>92.6</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>...</td>\n",
       "      <td>7.4</td>\n",
       "      <td>65.9</td>\n",
       "      <td>7.4</td>\n",
       "      <td>71.8</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cleaned_2023-12-21.csv</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>97.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>...</td>\n",
       "      <td>2.4</td>\n",
       "      <td>79.7</td>\n",
       "      <td>2.4</td>\n",
       "      <td>75.8</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cleaned_2023-12-22.csv</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.4</td>\n",
       "      <td>88.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>11.4</td>\n",
       "      <td>11.4</td>\n",
       "      <td>11.4</td>\n",
       "      <td>11.4</td>\n",
       "      <td>11.4</td>\n",
       "      <td>...</td>\n",
       "      <td>11.4</td>\n",
       "      <td>83.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>82.4</td>\n",
       "      <td>12.9</td>\n",
       "      <td>11.4</td>\n",
       "      <td>11.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows √ó 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     file  timestamp_iso  accelerometers_std_g  \\\n",
       "0  cleaned_2023-12-16.csv            0.0                   0.2   \n",
       "1  cleaned_2023-12-17.csv            0.0                   0.0   \n",
       "2  cleaned_2023-12-18.csv            0.0                   0.1   \n",
       "3  cleaned_2023-12-19.csv            0.0                   2.5   \n",
       "4  cleaned_2023-12-20.csv            0.0                   7.4   \n",
       "5  cleaned_2023-12-21.csv            0.0                   2.4   \n",
       "6  cleaned_2023-12-22.csv            0.0                  11.4   \n",
       "\n",
       "   missing_value_reason  counts_x_axis  counts_y_axis  counts_z_axis  \\\n",
       "0                  99.8            0.2            0.2            0.2   \n",
       "1                   NaN            0.0            0.0            0.0   \n",
       "2                  99.9            0.1            0.1            0.1   \n",
       "3                  97.5            2.5            2.5            2.5   \n",
       "4                  92.6            7.4            7.4            7.4   \n",
       "5                  97.6            2.4            2.4            2.4   \n",
       "6                  88.6           11.4           11.4           11.4   \n",
       "\n",
       "   vector_magnitude  activity_class  activity_counts  ...   met  prv_rmssd_ms  \\\n",
       "0               0.2             0.2              0.2  ...   0.2          96.8   \n",
       "1               0.0             0.0              0.0  ...   0.0          69.7   \n",
       "2               0.1             0.1              0.1  ...   0.1          88.3   \n",
       "3               2.5             2.5              2.5  ...   2.5          79.9   \n",
       "4               7.4             7.4              7.4  ...   7.4          65.9   \n",
       "5               2.4             2.4              2.4  ...   2.4          79.7   \n",
       "6              11.4            11.4             11.4  ...  11.4          83.6   \n",
       "\n",
       "   pulse_rate_bpm  respiratory_rate_brpm  sleep_detection_stage  step_counts  \\\n",
       "0             0.2                   87.9                    0.2          0.2   \n",
       "1             0.0                   76.2                    0.0          0.0   \n",
       "2             0.1                   82.0                    0.1          0.1   \n",
       "3             2.5                   79.0                    2.5          2.5   \n",
       "4             7.4                   71.8                    7.4          7.4   \n",
       "5             2.4                   75.8                    2.4          2.4   \n",
       "6            11.4                   82.4                   12.9         11.4   \n",
       "\n",
       "   temperature_celsius  wearing_detection_percentage  hour  minute  \n",
       "0                  0.2                           0.0   0.0     0.0  \n",
       "1                  0.0                           0.0   0.0     0.0  \n",
       "2                  0.1                           0.0   0.0     0.0  \n",
       "3                  2.5                           0.0   0.0     0.0  \n",
       "4                  7.4                           0.0   0.0     0.0  \n",
       "5                  2.4                           0.0   0.0     0.0  \n",
       "6                 11.4                           0.0   0.0     0.0  \n",
       "\n",
       "[7 rows x 24 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('participant9_na_summary.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931c5b50",
   "metadata": {},
   "source": [
    "# Step 2: combine all participants and their modalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "89a5350d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Final master file saved: all_participants_cleaned_features.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory containing all cleaned participant folders\n",
    "base_dir = \"C:/Users/lpnhu/Downloads/Stress_Testing_Analysis/data/cleaned_biomarkers\"\n",
    "\n",
    "# Collect data from all participants\n",
    "all_participants = []\n",
    "\n",
    "for folder_name in sorted(os.listdir(base_dir)):\n",
    "    if not folder_name.startswith(\"cleaned_\"):\n",
    "        continue  # Skip non-participant folders\n",
    "\n",
    "    participant_id = folder_name.replace(\"cleaned_\", \"\")  # e.g., '01'\n",
    "    folder_path = os.path.join(base_dir, folder_name)\n",
    "\n",
    "    daily_data = []\n",
    "    for file in sorted(os.listdir(folder_path)):\n",
    "        if file.endswith(\".csv\"):\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            \n",
    "            # Extract date string from filename\n",
    "            date_str = file.replace(\"cleaned_\", \"\").replace(\".csv\", \"\")  # e.g., \"2023-12-24\"\n",
    "            \n",
    "            # Load CSV and tag with participant and date\n",
    "            df = pd.read_csv(file_path)\n",
    "            df[\"participant_id\"] = participant_id\n",
    "            df[\"date\"] = date_str\n",
    "            \n",
    "            daily_data.append(df)\n",
    "\n",
    "    # Merge all days for the participant\n",
    "    if daily_data:\n",
    "        participant_df = pd.concat(daily_data, ignore_index=True)\n",
    "        all_participants.append(participant_df)\n",
    "\n",
    "# Merge all participants into one dataset\n",
    "master_df = pd.concat(all_participants, ignore_index=True)\n",
    "\n",
    "# Save the result\n",
    "master_df.to_csv(\"all_participants_cleaned_features.csv\", index=False)\n",
    "print(\"‚úÖ Final master file saved: all_participants_cleaned_features.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f9e10d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp_iso</th>\n",
       "      <th>accelerometers_std_g</th>\n",
       "      <th>counts_x_axis</th>\n",
       "      <th>counts_y_axis</th>\n",
       "      <th>counts_z_axis</th>\n",
       "      <th>vector_magnitude</th>\n",
       "      <th>activity_class</th>\n",
       "      <th>activity_counts</th>\n",
       "      <th>activity_intensity</th>\n",
       "      <th>body_position_left</th>\n",
       "      <th>...</th>\n",
       "      <th>step_counts</th>\n",
       "      <th>temperature_celsius</th>\n",
       "      <th>wearing_detection_percentage</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>date</th>\n",
       "      <th>missing_value_reason</th>\n",
       "      <th>prv_rmssd_ms</th>\n",
       "      <th>respiratory_rate_brpm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-12-24 23:58:00+00:00</td>\n",
       "      <td>0.176</td>\n",
       "      <td>776.0</td>\n",
       "      <td>1938.0</td>\n",
       "      <td>1869.0</td>\n",
       "      <td>2801.0</td>\n",
       "      <td>generic</td>\n",
       "      <td>57.0</td>\n",
       "      <td>MPA</td>\n",
       "      <td>standing</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>30.08</td>\n",
       "      <td>100.0</td>\n",
       "      <td>23</td>\n",
       "      <td>58</td>\n",
       "      <td>01</td>\n",
       "      <td>2023-12-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-12-25 00:00:00+00:00</td>\n",
       "      <td>0.122</td>\n",
       "      <td>441.0</td>\n",
       "      <td>1238.0</td>\n",
       "      <td>684.0</td>\n",
       "      <td>1481.0</td>\n",
       "      <td>generic</td>\n",
       "      <td>53.0</td>\n",
       "      <td>sedentary</td>\n",
       "      <td>sitting_reclining_lying</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>32.21</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>01</td>\n",
       "      <td>2023-12-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-12-25 00:01:00+00:00</td>\n",
       "      <td>0.025</td>\n",
       "      <td>483.0</td>\n",
       "      <td>1385.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1786.0</td>\n",
       "      <td>generic</td>\n",
       "      <td>61.0</td>\n",
       "      <td>sedentary</td>\n",
       "      <td>sitting_reclining_lying</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.56</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>2023-12-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-12-25 00:02:00+00:00</td>\n",
       "      <td>0.036</td>\n",
       "      <td>1098.0</td>\n",
       "      <td>1086.0</td>\n",
       "      <td>824.0</td>\n",
       "      <td>1750.0</td>\n",
       "      <td>generic</td>\n",
       "      <td>69.0</td>\n",
       "      <td>LPA</td>\n",
       "      <td>sitting_reclining_lying</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>32.82</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>01</td>\n",
       "      <td>2023-12-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-12-25 00:03:00+00:00</td>\n",
       "      <td>0.034</td>\n",
       "      <td>1494.0</td>\n",
       "      <td>1767.0</td>\n",
       "      <td>833.0</td>\n",
       "      <td>2459.0</td>\n",
       "      <td>generic</td>\n",
       "      <td>76.0</td>\n",
       "      <td>LPA</td>\n",
       "      <td>sitting_reclining_lying</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32.95</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>01</td>\n",
       "      <td>2023-12-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101705</th>\n",
       "      <td>2023-12-22 17:32:00+00:00</td>\n",
       "      <td>0.107</td>\n",
       "      <td>2175.0</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>2321.0</td>\n",
       "      <td>3771.0</td>\n",
       "      <td>walking</td>\n",
       "      <td>148.0</td>\n",
       "      <td>MPA</td>\n",
       "      <td>standing</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>30.37</td>\n",
       "      <td>100.0</td>\n",
       "      <td>17</td>\n",
       "      <td>32</td>\n",
       "      <td>09</td>\n",
       "      <td>2023-12-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101706</th>\n",
       "      <td>2023-12-22 17:33:00+00:00</td>\n",
       "      <td>0.058</td>\n",
       "      <td>1605.0</td>\n",
       "      <td>1090.0</td>\n",
       "      <td>1537.0</td>\n",
       "      <td>2475.0</td>\n",
       "      <td>generic</td>\n",
       "      <td>132.0</td>\n",
       "      <td>LPA</td>\n",
       "      <td>sitting_reclining_lying</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>30.07</td>\n",
       "      <td>100.0</td>\n",
       "      <td>17</td>\n",
       "      <td>33</td>\n",
       "      <td>09</td>\n",
       "      <td>2023-12-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101707</th>\n",
       "      <td>2023-12-22 17:34:00+00:00</td>\n",
       "      <td>0.104</td>\n",
       "      <td>1892.0</td>\n",
       "      <td>1306.0</td>\n",
       "      <td>1686.0</td>\n",
       "      <td>2850.0</td>\n",
       "      <td>walking</td>\n",
       "      <td>139.0</td>\n",
       "      <td>LPA</td>\n",
       "      <td>miscellaneous</td>\n",
       "      <td>...</td>\n",
       "      <td>59.0</td>\n",
       "      <td>29.83</td>\n",
       "      <td>100.0</td>\n",
       "      <td>17</td>\n",
       "      <td>34</td>\n",
       "      <td>09</td>\n",
       "      <td>2023-12-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101708</th>\n",
       "      <td>2023-12-22 17:35:00+00:00</td>\n",
       "      <td>0.072</td>\n",
       "      <td>886.0</td>\n",
       "      <td>1604.0</td>\n",
       "      <td>1837.0</td>\n",
       "      <td>2594.0</td>\n",
       "      <td>generic</td>\n",
       "      <td>143.0</td>\n",
       "      <td>sedentary</td>\n",
       "      <td>standing</td>\n",
       "      <td>...</td>\n",
       "      <td>52.0</td>\n",
       "      <td>29.42</td>\n",
       "      <td>100.0</td>\n",
       "      <td>17</td>\n",
       "      <td>35</td>\n",
       "      <td>09</td>\n",
       "      <td>2023-12-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101709</th>\n",
       "      <td>2023-12-22 17:36:00+00:00</td>\n",
       "      <td>0.093</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>1359.0</td>\n",
       "      <td>1906.0</td>\n",
       "      <td>2567.0</td>\n",
       "      <td>generic</td>\n",
       "      <td>137.0</td>\n",
       "      <td>LPA</td>\n",
       "      <td>standing</td>\n",
       "      <td>...</td>\n",
       "      <td>39.0</td>\n",
       "      <td>29.14</td>\n",
       "      <td>100.0</td>\n",
       "      <td>17</td>\n",
       "      <td>36</td>\n",
       "      <td>09</td>\n",
       "      <td>2023-12-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101710 rows √ó 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    timestamp_iso  accelerometers_std_g  counts_x_axis  \\\n",
       "0       2023-12-24 23:58:00+00:00                 0.176          776.0   \n",
       "1       2023-12-25 00:00:00+00:00                 0.122          441.0   \n",
       "2       2023-12-25 00:01:00+00:00                 0.025          483.0   \n",
       "3       2023-12-25 00:02:00+00:00                 0.036         1098.0   \n",
       "4       2023-12-25 00:03:00+00:00                 0.034         1494.0   \n",
       "...                           ...                   ...            ...   \n",
       "101705  2023-12-22 17:32:00+00:00                 0.107         2175.0   \n",
       "101706  2023-12-22 17:33:00+00:00                 0.058         1605.0   \n",
       "101707  2023-12-22 17:34:00+00:00                 0.104         1892.0   \n",
       "101708  2023-12-22 17:35:00+00:00                 0.072          886.0   \n",
       "101709  2023-12-22 17:36:00+00:00                 0.093         1055.0   \n",
       "\n",
       "        counts_y_axis  counts_z_axis  vector_magnitude activity_class  \\\n",
       "0              1938.0         1869.0            2801.0        generic   \n",
       "1              1238.0          684.0            1481.0        generic   \n",
       "2              1385.0         1019.0            1786.0        generic   \n",
       "3              1086.0          824.0            1750.0        generic   \n",
       "4              1767.0          833.0            2459.0        generic   \n",
       "...               ...            ...               ...            ...   \n",
       "101705         2027.0         2321.0            3771.0        walking   \n",
       "101706         1090.0         1537.0            2475.0        generic   \n",
       "101707         1306.0         1686.0            2850.0        walking   \n",
       "101708         1604.0         1837.0            2594.0        generic   \n",
       "101709         1359.0         1906.0            2567.0        generic   \n",
       "\n",
       "        activity_counts activity_intensity       body_position_left  ...  \\\n",
       "0                  57.0                MPA                 standing  ...   \n",
       "1                  53.0          sedentary  sitting_reclining_lying  ...   \n",
       "2                  61.0          sedentary  sitting_reclining_lying  ...   \n",
       "3                  69.0                LPA  sitting_reclining_lying  ...   \n",
       "4                  76.0                LPA  sitting_reclining_lying  ...   \n",
       "...                 ...                ...                      ...  ...   \n",
       "101705            148.0                MPA                 standing  ...   \n",
       "101706            132.0                LPA  sitting_reclining_lying  ...   \n",
       "101707            139.0                LPA            miscellaneous  ...   \n",
       "101708            143.0          sedentary                 standing  ...   \n",
       "101709            137.0                LPA                 standing  ...   \n",
       "\n",
       "       step_counts  temperature_celsius  wearing_detection_percentage  hour  \\\n",
       "0             25.0                30.08                         100.0    23   \n",
       "1              8.0                32.21                         100.0     0   \n",
       "2              0.0                32.56                         100.0     0   \n",
       "3              6.0                32.82                         100.0     0   \n",
       "4              5.0                32.95                         100.0     0   \n",
       "...            ...                  ...                           ...   ...   \n",
       "101705        44.0                30.37                         100.0    17   \n",
       "101706        15.0                30.07                         100.0    17   \n",
       "101707        59.0                29.83                         100.0    17   \n",
       "101708        52.0                29.42                         100.0    17   \n",
       "101709        39.0                29.14                         100.0    17   \n",
       "\n",
       "        minute  participant_id        date  missing_value_reason  \\\n",
       "0           58              01  2023-12-24                   NaN   \n",
       "1            0              01  2023-12-25                   NaN   \n",
       "2            1              01  2023-12-25                   NaN   \n",
       "3            2              01  2023-12-25                   NaN   \n",
       "4            3              01  2023-12-25                   NaN   \n",
       "...        ...             ...         ...                   ...   \n",
       "101705      32              09  2023-12-22                   NaN   \n",
       "101706      33              09  2023-12-22                   NaN   \n",
       "101707      34              09  2023-12-22                   NaN   \n",
       "101708      35              09  2023-12-22                   NaN   \n",
       "101709      36              09  2023-12-22                   NaN   \n",
       "\n",
       "        prv_rmssd_ms  respiratory_rate_brpm  \n",
       "0                NaN                    NaN  \n",
       "1                NaN                    NaN  \n",
       "2                NaN                    NaN  \n",
       "3                NaN                    NaN  \n",
       "4                NaN                    NaN  \n",
       "...              ...                    ...  \n",
       "101705           NaN                    NaN  \n",
       "101706           NaN                    NaN  \n",
       "101707           NaN                    NaN  \n",
       "101708           NaN                    NaN  \n",
       "101709           NaN                    NaN  \n",
       "\n",
       "[101710 rows x 25 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e001fbec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp_iso                      0\n",
       "accelerometers_std_g               0\n",
       "counts_x_axis                      0\n",
       "counts_y_axis                      0\n",
       "counts_z_axis                      0\n",
       "vector_magnitude                   0\n",
       "activity_class                  3885\n",
       "activity_counts                    0\n",
       "activity_intensity              3885\n",
       "body_position_left              3974\n",
       "body_position_right             3974\n",
       "eda_scl_usiemens                   0\n",
       "met                                0\n",
       "pulse_rate_bpm                     0\n",
       "sleep_detection_stage              0\n",
       "step_counts                        0\n",
       "temperature_celsius                0\n",
       "wearing_detection_percentage       0\n",
       "hour                               0\n",
       "minute                             0\n",
       "participant_id                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c7fdd046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 columns with more than 25% missing values:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Set threshold (25% of total number of rows)\n",
    "threshold_col = 0.25 * len(master_df)\n",
    "\n",
    "# Identify columns with >25% missing values\n",
    "cols_to_drop = master_df.columns[master_df.isnull().sum() > threshold_col]\n",
    "\n",
    "# Drop those columns\n",
    "master_df = master_df.drop(columns=cols_to_drop)\n",
    "\n",
    "# Print confirmation\n",
    "print(f\"Dropped {len(cols_to_drop)} columns with more than 25% missing values:\")\n",
    "print(cols_to_drop.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8985669a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['date'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 1. Drop the 'date' column (optional if already removed)\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m master_df \u001b[38;5;241m=\u001b[39m master_df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# 2. Identify numeric columns (excluding ID/timestamp)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m numeric_cols \u001b[38;5;241m=\u001b[39m master_df\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m[np\u001b[38;5;241m.\u001b[39mnumber])\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5446\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdrop(\n\u001b[0;32m   5582\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[0;32m   5583\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   5584\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   5585\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   5586\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   5587\u001b[0m         inplace\u001b[38;5;241m=\u001b[39minplace,\n\u001b[0;32m   5588\u001b[0m         errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   5589\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_drop_axis(labels, axis, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4828\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4830\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4831\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4833\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['date'] not found in axis\""
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 1. Drop the 'date' column (optional if already removed)\n",
    "master_df = master_df.drop(columns=[\"date\"])\n",
    "\n",
    "# 2. Identify numeric columns (excluding ID/timestamp)\n",
    "numeric_cols = master_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numeric_cols = [col for col in numeric_cols if col not in [\"participant_id\", \"hour\", \"minute\"]]\n",
    "\n",
    "# 3. Impute missing values with median per participant\n",
    "master_df[numeric_cols] = (\n",
    "    master_df.groupby(\"participant_id\")[numeric_cols]\n",
    "    .transform(lambda x: x.fillna(x.median()))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fa81b15a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "activity_class         object\n",
       "activity_counts       float64\n",
       "activity_intensity     object\n",
       "body_position_left     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df.dtypes.loc[[\"activity_class\", \"activity_counts\", \"activity_intensity\", \"body_position_left\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "60697ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column: activity_class\n",
      "activity_class\n",
      "still      49105\n",
      "generic    38634\n",
      "walking     9926\n",
      "running      160\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: activity_intensity\n",
      "activity_intensity\n",
      "sedentary    57555\n",
      "LPA          22122\n",
      "MPA          14501\n",
      "VPA           3647\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: body_position_left\n",
      "body_position_left\n",
      "sitting_reclining_lying    61853\n",
      "standing                   32746\n",
      "miscellaneous               3137\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "cols_to_check = [\"activity_class\", \"activity_intensity\", \"body_position_left\"]\n",
    "\n",
    "for col in cols_to_check:\n",
    "    print(f\"\\nColumn: {col}\")\n",
    "    print(master_df[col].dropna().value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "144220b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_class_map = {'still': 0, 'generic': 1, 'walking': 2, 'running': 3}\n",
    "master_df['activity_class'] = master_df['activity_class'].map(activity_class_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a8179fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_intensity_map = {'sedentary': 0, 'LPA': 1, 'MPA': 2, 'VPA': 3}\n",
    "master_df['activity_intensity'] = master_df['activity_intensity'].map(activity_intensity_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "09386d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df['body_position_left'], _ = pd.factorize(master_df['body_position_left'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fab74996",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df['body_position_right'], _ = pd.factorize(master_df['body_position_right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e01850c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp_iso                      0\n",
       "accelerometers_std_g               0\n",
       "counts_x_axis                      0\n",
       "counts_y_axis                      0\n",
       "counts_z_axis                      0\n",
       "vector_magnitude                   0\n",
       "activity_class                  3885\n",
       "activity_counts                    0\n",
       "activity_intensity              3885\n",
       "body_position_left                 0\n",
       "body_position_right             3974\n",
       "eda_scl_usiemens                   0\n",
       "met                                0\n",
       "pulse_rate_bpm                     0\n",
       "sleep_detection_stage              0\n",
       "step_counts                        0\n",
       "temperature_celsius                0\n",
       "wearing_detection_percentage       0\n",
       "hour                               0\n",
       "minute                             0\n",
       "participant_id                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fc76aa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to impute\n",
    "cat_cols = ['activity_class', 'activity_intensity', 'body_position_left', 'body_position_right']\n",
    "\n",
    "# Fill NaNs using median per participant\n",
    "master_df[cat_cols] = (\n",
    "    master_df.groupby(\"participant_id\")[cat_cols]\n",
    "    .transform(lambda x: x.fillna(x.median()))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9d51fcbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp_iso                   0\n",
       "accelerometers_std_g            0\n",
       "counts_x_axis                   0\n",
       "counts_y_axis                   0\n",
       "counts_z_axis                   0\n",
       "vector_magnitude                0\n",
       "activity_class                  0\n",
       "activity_counts                 0\n",
       "activity_intensity              0\n",
       "body_position_left              0\n",
       "body_position_right             0\n",
       "eda_scl_usiemens                0\n",
       "met                             0\n",
       "pulse_rate_bpm                  0\n",
       "sleep_detection_stage           0\n",
       "step_counts                     0\n",
       "temperature_celsius             0\n",
       "wearing_detection_percentage    0\n",
       "hour                            0\n",
       "minute                          0\n",
       "participant_id                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "41a3436a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved cleaned data to: C:/Users/lpnhu/Downloads/Stress_Testing_Analysis/data/cleaned_master_df.csv\n"
     ]
    }
   ],
   "source": [
    "output_path = \"C:/Users/lpnhu/Downloads/Stress_Testing_Analysis/data/cleaned_master_df.csv\"\n",
    "master_df.to_csv(output_path, index=False)\n",
    "print(f\"‚úÖ Saved cleaned data to: {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
